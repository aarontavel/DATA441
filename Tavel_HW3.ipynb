{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMlL/+ppQq4W2m+9KaCgrvO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarontavel/DATA441/blob/main/Tavel_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install skorch"
      ],
      "metadata": {
        "id": "TKN-fxJWg4yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # we are going to use pytorch instead of numpy because it's much faster.\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
        "from sklearn.datasets import make_spd_matrix\n",
        "from scipy.optimize import minimize\n",
        "from scipy.linalg import toeplitz\n",
        "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, r2_score as R2\n",
        "from sklearn.model_selection import train_test_split as tts, KFold, GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.linalg import toeplitz\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n"
      ],
      "metadata": {
        "id": "oo9JABm8ULZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFFrQA9Gehr_",
        "outputId": "793533a2-8e9a-419d-fcf3-8d098cc7767c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. (5 points) Create your own PyTorch class that implements the method of SCAD regularization and variable selection (smoothly clipped absolute deviations) for linear models."
      ],
      "metadata": {
        "id": "V0fYugeJUIKu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udz5uWZKN1HN"
      },
      "outputs": [],
      "source": [
        "class SCAD(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, alpha = 0.25, lambda_val = 0.001, epoch = 5000, learning_rate = 0.0001, scaler = None):\n",
        "    super(SCAD, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.alpha = alpha\n",
        "    self.lambda_val = lambda_val\n",
        "    self.epoch = epoch\n",
        "    self.learning_rate = learning_rate\n",
        "    self.scaler = scaler\n",
        "    self._is_fitted = False\n",
        "\n",
        "    # Defining Linear Regression\n",
        "    self.linear = nn.Linear(input_size, 1, bias = False, device = device)\n",
        "\n",
        "    self.beta_hat = nn.Parameter(torch.randn((input_size,1), dtype = torch.float64, requires_grad=True)) # Initializes weights\n",
        "\n",
        "  def _scale_data(self, x):\n",
        "    if self.scaler is not None:\n",
        "      scaled_data = self.scaler.fit_transform(x)\n",
        "      return torch.tensor(scaled_data, dtype=torch.float64)\n",
        "    else:\n",
        "      return torch.tensor(x, dtype=torch.float64, requires_grad=True)\n",
        "\n",
        "  def scad_penalty(self):\n",
        "\n",
        "    is_linear = torch.abs(self.beta_hat) <= self.lambda_val\n",
        "    is_quadratic = (self.lambda_val < torch.abs(self.beta_hat)) & (torch.abs(self.beta_hat) <= self.alpha * self.lambda_val)\n",
        "    is_constant = (self.alpha * self.lambda_val) < torch.abs(self.beta_hat)\n",
        "\n",
        "    linear_part = self.lambda_val * torch.abs(self.beta_hat) * is_linear.float()\n",
        "    quadratic_part = (2 * self.alpha * self.lambda_val * torch.abs(self.beta_hat) - self.beta_hat**2 - self.lambda_val**2) / (2 * (self.alpha - 1)) * is_quadratic.float()\n",
        "    constant_part = (self.lambda_val**2 * (self.alpha + 1)) / 2 * is_constant.float()\n",
        "\n",
        "    return linear_part + quadratic_part + constant_part\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_tensor = self._scale_data(x)\n",
        "\n",
        "    return torch.matmul(x_tensor, self.beta_hat)\n",
        "\n",
        "  def loss(self, x, y_pred, y_train):\n",
        "\n",
        "    y_train_tensor = torch.tensor(y_train, dtype = torch.float64).flatten()\n",
        "\n",
        "    mse_loss = nn.MSELoss()(y_pred.flatten(), y_train_tensor)\n",
        "\n",
        "    scad_penalty = torch.sum(self.scad_penalty())\n",
        "\n",
        "    total_loss = mse_loss + scad_penalty\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "  def fit(self, x, y_train): #takes y_train\n",
        "\n",
        "    optimizer = torch.optim.Adam([self.beta_hat], lr = self.learning_rate)\n",
        "\n",
        "    for epoch in range(self.epoch):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      predictions = self.forward(x)\n",
        "\n",
        "      loss = self.loss(x, predictions, y_train)\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      #if (epoch + 1) % 500 == 0:\n",
        "        #print(f\"Epoch [{epoch + 1}/{self.epoch}], Loss: {loss.item()}\")\n",
        "\n",
        "    self._is_fitted = True\n",
        "\n",
        "  def predict(self, x):\n",
        "    x_tensor = self._scale_data(x)\n",
        "\n",
        "    return self.forward(x_tensor)\n",
        "\n",
        "  def get_coefficients(self):\n",
        "\n",
        "    return self.beta_hat.detach().clone()\n",
        "\n",
        "  def is_fitted(self):\n",
        "    return self._is_fitted"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing Question 1"
      ],
      "metadata": {
        "id": "rMazn_hjemF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "dtype = torch.float64"
      ],
      "metadata": {
        "id": "wVtvwyyGfyCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Sophomore Year/DATA/DATA-310/Module 3/Regression Problems/Data/concrete.csv\")"
      ],
      "metadata": {
        "id": "3qyD48CFWmLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = data.loc[:,'cement':'age'].values\n",
        "y = data['strength'].values"
      ],
      "metadata": {
        "id": "PqszJn7UepMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "mse_scad = []\n",
        "\n",
        "scale = StandardScaler()\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
        "\n",
        "for idxtrain, idxtest in kf.split(x):\n",
        "    xtrain = x[idxtrain]\n",
        "    ytrain = y[idxtrain]\n",
        "    ytest = y[idxtest]\n",
        "    xtest = x[idxtest]\n",
        "\n",
        "    xtrain_scaled = scale.fit_transform(xtrain)\n",
        "    xtest_scaled = scale.transform(xtest)\n",
        "\n",
        "    model = SCAD(input_size=x.shape[1], scaler=scale, alpha=0.25, lambda_val=0.001, learning_rate=0.0001)\n",
        "    model.fit(xtrain_scaled, ytrain)\n",
        "    yhat = model.predict(xtest_scaled).detach().numpy()\n",
        "\n",
        "    mse_fold = mean_squared_error(ytest, yhat)\n",
        "    mse_scad.append(mse_fold)"
      ],
      "metadata": {
        "id": "NnZfBbG2kpa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Cross-validated Mean Squared Error for SCAD is:', np.mean(mse_scad))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUSABahCmnAs",
        "outputId": "7b05a9b1-0e5d-4fb5-ee71-85249c9bdda5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Cross-validated Mean Squared Error for SCAD is: 1540.5411640543618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_coefficients()"
      ],
      "metadata": {
        "id": "PGUoeoSZlI8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ca5e04-d6ac-47e3-dd75-e4188ac56e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5772],\n",
              "        [ 1.7974],\n",
              "        [-1.0598],\n",
              "        [-1.9131],\n",
              "        [-0.9208],\n",
              "        [-0.2894],\n",
              "        [-0.4967],\n",
              "        [ 0.3871]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Based on the simulation design explained in class, generate 500 data sets where the input features have a strong correlation structure (you may consider a 0.9) and apply ElasticNet, SqrtLasso and SCAD to check which method produces the best approximation of an ideal solution, such as a \"betastar\" you design with a sparsity pattern."
      ],
      "metadata": {
        "id": "qlGd07FMzM6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ElasticNet(nn.Module):\n",
        "    def __init__(self, input_size, alpha=1.0, l1_ratio=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the ElasticNet regression model.\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Number of input features.\n",
        "            alpha (float): Regularization strength. Higher values of alpha\n",
        "                emphasize L1 regularization, while lower values emphasize L2 regularization.\n",
        "            l1_ratio (float): The ratio of L1 regularization to the total\n",
        "                regularization (L1 + L2). It should be between 0 and 1.\n",
        "\n",
        "        \"\"\"\n",
        "        super(ElasticNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.alpha = alpha\n",
        "        self.l1_ratio = l1_ratio\n",
        "\n",
        "        # Define the linear regression layer\n",
        "        self.linear = nn.Linear(input_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the ElasticNet model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input data with shape (batch_size, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (batch_size, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Compute the ElasticNet loss function.\n",
        "\n",
        "        Args:\n",
        "            y_pred (Tensor): Predicted values with shape (batch_size, 1).\n",
        "            y_true (Tensor): True target values with shape (batch_size, 1).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The ElasticNet loss.\n",
        "\n",
        "        \"\"\"\n",
        "        mse_loss = nn.MSELoss()(y_pred, y_true)\n",
        "        l1_reg = torch.norm(self.linear.weight, p=1)\n",
        "        l2_reg = torch.norm(self.linear.weight, p=2)\n",
        "\n",
        "        loss = mse_loss + self.alpha * (\n",
        "            self.l1_ratio * l1_reg + (1 - self.l1_ratio) * l2_reg\n",
        "        )\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y, num_epochs=100, learning_rate=0.01):\n",
        "        \"\"\"\n",
        "        Fit the ElasticNet model to the training data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "            y (Tensor): Target values with shape (num_samples, 1).\n",
        "            num_epochs (int): Number of training epochs.\n",
        "            learning_rate (float): Learning rate for optimization.\n",
        "\n",
        "        \"\"\"\n",
        "        optimizer = optim.SGD(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.train()\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = self(X)\n",
        "            loss = self.loss(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict target values for input data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (num_samples, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = self(X)\n",
        "        return y_pred\n",
        "    def get_coefficients(self):\n",
        "        \"\"\"\n",
        "        Get the coefficients (weights) of the linear regression layer.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Coefficients with shape (output_size, input_size).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear.weight\n"
      ],
      "metadata": {
        "id": "RlehnZ4EzXnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can call this version PED_Adam because we use the adaptive momentum gradient descent for optimization\n",
        "class sqrtLasso(nn.Module):\n",
        "    def __init__(self, input_size, alpha=0.1):\n",
        "        \"\"\"\n",
        "        Initialize the  regression model.\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        super(sqrtLasso, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.alpha = alpha\n",
        "\n",
        "\n",
        "        # Define the linear regression layer\n",
        "        self.linear = nn.Linear(input_size, 1).double()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input data with shape (batch_size, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (batch_size, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Compute the loss function.\n",
        "\n",
        "        Args:\n",
        "            y_pred (Tensor): Predicted values with shape (batch_size, 1).\n",
        "            y_true (Tensor): True target values with shape (batch_size, 1).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The loss.\n",
        "\n",
        "        \"\"\"\n",
        "        mse_loss = nn.MSELoss()(y_pred, y_true)\n",
        "        l1_reg = torch.norm(self.linear.weight, p=1,dtype=torch.float64)\n",
        "        # l2_reg = torch.norm(self.linear.weight, p=2,dtype=torch.float64)\n",
        "\n",
        "        loss = (len(y_true)*mse_loss)**(1/2) + self.alpha * (l1_reg)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y, num_epochs=200, learning_rate=0.01):\n",
        "        \"\"\"\n",
        "        Fit the model to the training data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "            y (Tensor): Target values with shape (num_samples, 1).\n",
        "            num_epochs (int): Number of training epochs.\n",
        "            learning_rate (float): Learning rate for optimization.\n",
        "\n",
        "        \"\"\"\n",
        "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.train()\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = self(X)\n",
        "            loss = self.loss(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict target values for input data.\n",
        "\n",
        "        Args:\n",
        "            X (Tensor): Input data with shape (num_samples, input_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predicted values with shape (num_samples, 1).\n",
        "\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = self(X)\n",
        "        return y_pred\n",
        "    def get_coefficients(self):\n",
        "        \"\"\"\n",
        "        Get the coefficients (weights) of the linear regression layer.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Coefficients with shape (output_size, input_size).\n",
        "\n",
        "        \"\"\"\n",
        "        return self.linear.weight"
      ],
      "metadata": {
        "id": "3OZRU4GGzalL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "0TvdCeYhKi_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scale = StandardScaler()"
      ],
      "metadata": {
        "id": "_2WA1G5KD6Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_correlated_features(num_samples,p,rho):\n",
        "  vcor = []\n",
        "  for i in range(p):\n",
        "    vcor.append(rho**i)\n",
        "  r = toeplitz(vcor)\n",
        "  mu = np.repeat(0,p)\n",
        "  x = np.random.multivariate_normal(mu, r, size=num_samples)\n",
        "  return x"
      ],
      "metadata": {
        "id": "dl1PlXSTzaim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rho =0.9 # correlation\n",
        "p = 200 # predictors\n",
        "n = 150 # number of variables\n",
        "vcor = []\n",
        "for i in range(p):\n",
        "  vcor.append(rho**i)"
      ],
      "metadata": {
        "id": "W1Oaop4FzafK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta =np.array([-1,2,3,0,0,0,0,2,-1,4])\n",
        "beta = beta.reshape(-1,1)\n",
        "betastar = np.concatenate([beta,np.repeat(0,p-len(beta)).reshape(-1,1)],axis=0)"
      ],
      "metadata": {
        "id": "w4jk4mV0Klo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SCAD -- This code is taking too long to run. It was completing approximately 5 iterations/minute which would take too long and my computer was overheating.\n",
        "# I will write code below for what i would do in order to complete the question.\n",
        "\n",
        "all_betas = []\n",
        "\n",
        "for i in range(5):\n",
        "    individual_betas = []\n",
        "    x = make_correlated_features(n, p, rho)\n",
        "    y = x @ betastar + 0.5 * np.random.normal(size=(150, 1))\n",
        "\n",
        "    model = SCAD(input_size=x.shape[1], scaler=scale, alpha=0.25, lambda_val=0.001, learning_rate=0.0001)\n",
        "    model.fit(x, y)\n",
        "    coef = model.get_coefficients()\n",
        "\n",
        "    individual_betas.append(coef)\n",
        "    all_betas.append(individual_betas)\n",
        "\n",
        "# Convert the list of tensors to a single tensor\n",
        "all_betas_tensor = torch.stack([torch.stack(betas) for betas in all_betas])\n",
        "\n",
        "average_betas_SCAD = torch.mean(all_betas_tensor, dim=0)\n",
        "\n",
        "print(\"Average betas across iterations for:\", average_betas_SCAD)"
      ],
      "metadata": {
        "id": "Lvf0jg_IR7hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03220f3-195e-4473-c98b-088ba55836b4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average betas across iterations for: tensor([[[ 0.5080],\n",
            "         [ 0.8076],\n",
            "         [ 0.5827],\n",
            "         [ 0.3673],\n",
            "         [ 0.5758],\n",
            "         [ 0.4098],\n",
            "         [ 0.4298],\n",
            "         [-0.1010],\n",
            "         [ 0.2603],\n",
            "         [ 0.1118],\n",
            "         [ 0.6125],\n",
            "         [-0.1074],\n",
            "         [ 0.1397],\n",
            "         [-0.2210],\n",
            "         [-0.3646],\n",
            "         [ 0.5322],\n",
            "         [-0.1071],\n",
            "         [ 0.6398],\n",
            "         [ 0.1063],\n",
            "         [-0.1868],\n",
            "         [ 0.9004],\n",
            "         [-0.3061],\n",
            "         [ 0.2371],\n",
            "         [ 0.1242],\n",
            "         [-0.2953],\n",
            "         [ 0.2018],\n",
            "         [ 0.4716],\n",
            "         [ 0.2560],\n",
            "         [ 0.1037],\n",
            "         [-0.1330],\n",
            "         [-0.8828],\n",
            "         [ 0.4840],\n",
            "         [-0.5099],\n",
            "         [ 0.0033],\n",
            "         [ 0.0844],\n",
            "         [ 0.1751],\n",
            "         [-0.3028],\n",
            "         [ 0.3269],\n",
            "         [-0.1063],\n",
            "         [ 0.1428],\n",
            "         [-0.0401],\n",
            "         [-0.7981],\n",
            "         [ 0.0357],\n",
            "         [-0.2224],\n",
            "         [ 0.1382],\n",
            "         [-0.3540],\n",
            "         [ 0.1335],\n",
            "         [ 0.3392],\n",
            "         [ 0.1628],\n",
            "         [-0.0103],\n",
            "         [ 0.0596],\n",
            "         [ 0.3104],\n",
            "         [ 0.1404],\n",
            "         [-0.3315],\n",
            "         [ 0.1671],\n",
            "         [ 0.1138],\n",
            "         [-0.5729],\n",
            "         [-0.5206],\n",
            "         [-0.2131],\n",
            "         [-0.1821],\n",
            "         [ 0.3090],\n",
            "         [-0.1427],\n",
            "         [-0.0937],\n",
            "         [-0.1854],\n",
            "         [-0.0399],\n",
            "         [-0.1903],\n",
            "         [ 0.0941],\n",
            "         [ 0.3570],\n",
            "         [-0.5899],\n",
            "         [-0.1603],\n",
            "         [ 1.1152],\n",
            "         [ 0.6651],\n",
            "         [-0.1794],\n",
            "         [-0.3589],\n",
            "         [-0.1833],\n",
            "         [-0.5050],\n",
            "         [ 0.1640],\n",
            "         [ 1.2797],\n",
            "         [-0.9222],\n",
            "         [ 0.2143],\n",
            "         [-0.1061],\n",
            "         [-0.4201],\n",
            "         [ 0.2961],\n",
            "         [-0.0294],\n",
            "         [-0.1837],\n",
            "         [-0.2227],\n",
            "         [ 0.7105],\n",
            "         [-0.2429],\n",
            "         [ 0.0165],\n",
            "         [ 0.2311],\n",
            "         [-0.2277],\n",
            "         [-0.2790],\n",
            "         [ 0.2052],\n",
            "         [ 0.1456],\n",
            "         [ 0.2375],\n",
            "         [ 0.1897],\n",
            "         [-0.0295],\n",
            "         [ 0.5967],\n",
            "         [-0.2238],\n",
            "         [-0.0392],\n",
            "         [-0.0577],\n",
            "         [-0.1162],\n",
            "         [-1.1575],\n",
            "         [ 0.1581],\n",
            "         [ 0.3380],\n",
            "         [-0.6022],\n",
            "         [ 0.6081],\n",
            "         [-0.0751],\n",
            "         [-0.5165],\n",
            "         [ 0.4746],\n",
            "         [-0.5065],\n",
            "         [-0.3444],\n",
            "         [-0.0482],\n",
            "         [ 0.3555],\n",
            "         [-0.0923],\n",
            "         [-0.1592],\n",
            "         [ 0.8756],\n",
            "         [ 0.4680],\n",
            "         [-0.7292],\n",
            "         [-0.0888],\n",
            "         [ 0.4416],\n",
            "         [-0.9437],\n",
            "         [-0.0271],\n",
            "         [-0.0014],\n",
            "         [ 0.2436],\n",
            "         [-0.3781],\n",
            "         [ 0.5602],\n",
            "         [-0.6691],\n",
            "         [-0.0657],\n",
            "         [ 0.5466],\n",
            "         [ 0.0950],\n",
            "         [ 0.1236],\n",
            "         [ 0.1415],\n",
            "         [-1.2148],\n",
            "         [ 0.2273],\n",
            "         [-0.0066],\n",
            "         [-0.0648],\n",
            "         [ 1.0575],\n",
            "         [ 0.3867],\n",
            "         [-0.3689],\n",
            "         [-0.6710],\n",
            "         [-0.0150],\n",
            "         [ 0.6264],\n",
            "         [-0.4409],\n",
            "         [-0.1187],\n",
            "         [ 0.5018],\n",
            "         [-0.2356],\n",
            "         [-0.3735],\n",
            "         [-0.0088],\n",
            "         [ 0.4810],\n",
            "         [-0.5752],\n",
            "         [ 0.2621],\n",
            "         [-0.9405],\n",
            "         [ 0.4440],\n",
            "         [ 0.9706],\n",
            "         [-0.0983],\n",
            "         [-0.0024],\n",
            "         [-0.1605],\n",
            "         [ 0.3155],\n",
            "         [-0.5453],\n",
            "         [-0.3015],\n",
            "         [ 0.1627],\n",
            "         [ 0.0800],\n",
            "         [-0.2135],\n",
            "         [ 0.5381],\n",
            "         [-0.4739],\n",
            "         [-0.1118],\n",
            "         [-0.3319],\n",
            "         [ 0.7478],\n",
            "         [-0.4854],\n",
            "         [ 0.3052],\n",
            "         [-0.1644],\n",
            "         [ 0.0324],\n",
            "         [ 0.3485],\n",
            "         [-0.5845],\n",
            "         [ 0.6437],\n",
            "         [ 0.0829],\n",
            "         [-0.3326],\n",
            "         [ 0.5682],\n",
            "         [-0.8537],\n",
            "         [ 0.3184],\n",
            "         [-0.4937],\n",
            "         [-0.2709],\n",
            "         [-0.2501],\n",
            "         [ 0.0678],\n",
            "         [-0.3615],\n",
            "         [ 0.0071],\n",
            "         [ 0.4899],\n",
            "         [-0.1599],\n",
            "         [-0.2031],\n",
            "         [ 0.6442],\n",
            "         [-0.4923],\n",
            "         [ 0.6062],\n",
            "         [ 0.3778],\n",
            "         [-0.4056],\n",
            "         [-0.5291],\n",
            "         [ 0.6463],\n",
            "         [ 0.6510],\n",
            "         [-0.2565],\n",
            "         [-0.4858]]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ElasticNet -- this one runs much faster for some reason -- unsure why my SCAD takes so long\n",
        "\n",
        "all_betas = []\n",
        "\n",
        "for i in range(500):\n",
        "    individual_betas = []\n",
        "    x = make_correlated_features(n, p, rho)\n",
        "    y = x @ betastar + 0.5 * np.random.normal(size=(150, 1))\n",
        "\n",
        "    x_tensor = torch.tensor(x, dtype = torch.float64).float()\n",
        "    y_tensor = torch.tensor(y, dtype = torch.float64).float()\n",
        "\n",
        "    model = ElasticNet(input_size = x_tensor.shape[1])\n",
        "    model.fit(x_tensor, y_tensor)\n",
        "    coef = model.get_coefficients()\n",
        "\n",
        "    individual_betas.append(coef)\n",
        "    all_betas.append(individual_betas)\n",
        "\n",
        "all_betas_tensor = torch.stack([torch.stack(betas) for betas in all_betas])\n",
        "\n",
        "average_betas_eN = torch.mean(all_betas_tensor, dim=0)\n",
        "\n",
        "print(\"Average betas across iterations for ENet:\", average_betas_eN)"
      ],
      "metadata": {
        "id": "IDZRLcV9LutM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sqrtLASSO\n",
        "\n",
        "all_betas = []\n",
        "\n",
        "for i in range(500):\n",
        "    individual_betas = []\n",
        "    x = make_correlated_features(n, p, rho)\n",
        "    y = x @ betastar + 0.5 * np.random.normal(size=(150, 1))\n",
        "\n",
        "    x_tensor = torch.tensor(x, dtype = torch.float64).double()\n",
        "    y_tensor = torch.tensor(y, dtype = torch.float64).double()\n",
        "\n",
        "    model = sqrtLasso(input_size = x_tensor.shape[1])\n",
        "    model.fit(x_tensor, y_tensor)\n",
        "    coef = model.get_coefficients()\n",
        "\n",
        "    individual_betas.append(coef)\n",
        "    all_betas.append(individual_betas)\n",
        "\n",
        "# Convert the list of tensors to a single tensor\n",
        "all_betas_tensor = torch.stack([torch.stack(betas) for betas in all_betas])\n",
        "\n",
        "average_betas_sL = torch.mean(all_betas_tensor, dim=0)\n",
        "\n",
        "print(\"Average betas across iterations for sqrtLasso:\", average_betas_sL)"
      ],
      "metadata": {
        "id": "pMIKcfH2MjOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tvb3FCJ2S16c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}