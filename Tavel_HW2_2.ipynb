{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUpcllLdO7Ws1HvUr4UBNO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarontavel/DATA441/blob/main/Tavel_HW2_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy usearch"
      ],
      "metadata": {
        "id": "eG908n_3EU6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13b3602-aebf-45d9-fe47-d5c675970f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting usearch\n",
            "  Downloading usearch-2.9.0-cp310-cp310-manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from usearch) (4.66.2)\n",
            "Installing collected packages: usearch\n",
            "Successfully installed usearch-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHcJ1saMCnXa"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "import pandas as pd\n",
        "from sklearn import linear_model\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
        "from scipy.spatial import Delaunay\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from scipy import linalg\n",
        "from scipy.interpolate import interp1d, LinearNDInterpolator, NearestNDInterpolator\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split as tts, KFold, GridSearchCV\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# the following line(s) are necessary if you want to make SKlearn compliant functions\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from math import ceil\n",
        "\n",
        "from usearch.index import search, MetricKind, Matches, BatchMatches, Index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "033RD69rDO2X",
        "outputId": "6ef44079-cef7-46bf-f15f-566c45da83d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Gradient Boosting Class"
      ],
      "metadata": {
        "id": "6Az2_cq6DnrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Kernel\n",
        "def Gaussian(w):\n",
        "  return np.where(w>4,0,1/(np.sqrt(2*np.pi))*np.exp(-1/2*w**2))\n",
        "\n",
        "# Tricubic Kernel\n",
        "def Tricubic(w):\n",
        "  return np.where(w>1,0,70/81*(1-w**3)**3)\n",
        "\n",
        "# Quartic Kernel\n",
        "def Quartic(w):\n",
        "  return np.where(w>1,0,15/16*(1-w**2)**2)\n",
        "\n",
        "# Epanechnikov Kernel\n",
        "def Epanechnikov(w):\n",
        "  return np.where(w>1,0,3/4*(1-w**2))"
      ],
      "metadata": {
        "id": "XkAxrCE-SHe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lw_ag_md(x, y, xnew,f=2/3,iter=3, intercept=True):\n",
        "\n",
        "  n = len(x)\n",
        "  r = int(ceil(f * n))\n",
        "  yest = np.zeros(n)\n",
        "\n",
        "  if len(y.shape)==1: # here we make column vectors\n",
        "    y = y.reshape(-1,1)\n",
        "\n",
        "  if len(x.shape)==1:\n",
        "    x = x.reshape(-1,1)\n",
        "\n",
        "  if intercept:\n",
        "    x1 = np.column_stack([np.ones((len(x),1)),x])\n",
        "  else:\n",
        "    x1 = x\n",
        "\n",
        "  h = [np.sort(np.sqrt(np.sum((x-x[i])**2,axis=1)))[r] for i in range(n)]\n",
        "  # dist(x,x) is always symmetric\n",
        "  w = np.clip(dist(x,x) / np.array(h), 0.0, 1.0)\n",
        "  # note that w is a square matrix and in Python arithmetic operations such as\n",
        "  # w**3 or 1-w**3 are performed element-wise\n",
        "  #w = (1-w**3)**3 # a Tricubic kernel\n",
        "  w = Epanechnikov(w)\n",
        "\n",
        "  #Looping through all X-points\n",
        "  delta = np.ones(n)\n",
        "\n",
        "  for iteration in range(iter):\n",
        "    for i in range(n):\n",
        "      W = np.diag(delta).dot(np.diag(w[i,:]))\n",
        "      # when we multiply two diagonal matrices we get also a diagonal matrix\n",
        "      b = np.transpose(x1).dot(W).dot(y)\n",
        "      A = np.transpose(x1).dot(W).dot(x1)\n",
        "      ##\n",
        "      A = A + 0.0001*np.eye(x1.shape[1]) # if we want L2 regularization for solving the system\n",
        "      beta = linalg.solve(A, b)\n",
        "\n",
        "      #beta, res, rnk, s = linalg.lstsq(A, b)\n",
        "      yest[i] = np.dot(x1[i],beta.ravel())\n",
        "\n",
        "    residuals = y.ravel() - yest\n",
        "    s = np.median(np.abs(residuals))\n",
        "\n",
        "    delta = np.clip(residuals / (6.0 * s), -1, 1)\n",
        "\n",
        "    delta = (1 - delta ** 2) ** 2\n",
        "\n",
        "  # here we are making predictions for xnew by using an interpolation and the predictions we made for the train data\n",
        "  if x.shape[1]==1:\n",
        "    f = interp1d(x.flatten(),yest,fill_value='extrapolate')\n",
        "    output = f(xnew)\n",
        "  else:\n",
        "    output = np.zeros(len(xnew))\n",
        "    for i in range(len(xnew)):\n",
        "      ind = np.argsort(np.sqrt(np.sum((x-xnew[i])**2,axis=1)))[:r]\n",
        "      pca = PCA(n_components=3)\n",
        "      x_pca = pca.fit_transform(x[ind])\n",
        "      tri = Delaunay(x_pca,qhull_options='QJ Pp')\n",
        "      f = LinearNDInterpolator(tri,yest[ind])\n",
        "      output[i] = f(pca.transform(xnew[i].reshape(1,-1)))\n",
        "      # the output may have NaN's where the data points from xnew are outside the convex hull of X\n",
        "\n",
        "  if sum(np.isnan(output))>0:\n",
        "    g = NearestNDInterpolator(x,yest.ravel())\n",
        "    # output[np.isnan(output)] = g(X[np.isnan(output)])\n",
        "    output[np.isnan(output)] = g(xnew[np.isnan(output)])\n",
        "  return output"
      ],
      "metadata": {
        "id": "1-FtPOuFoSEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lowess_AG_MD: #Base class pulled from Professor's GitHub\n",
        "    def __init__(self, f = 1/10, iter = 3,intercept=True):\n",
        "        self.f = f\n",
        "        self.iter = iter\n",
        "        self.intercept = intercept\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        f = self.f\n",
        "        iter = self.iter\n",
        "        self.xtrain_ = x\n",
        "        self.yhat_ = y\n",
        "\n",
        "    def is_fitted(self):\n",
        "      return self._is_fitted\n",
        "\n",
        "    def predict(self, x_new):\n",
        "        check_is_fitted(self)\n",
        "        x = self.xtrain_\n",
        "        y = self.yhat_\n",
        "        f = self.f\n",
        "        iter = self.iter\n",
        "        intercept = self.intercept\n",
        "        return lw_ag_md(x, y, x_new, f, iter, intercept) # this is actually our defined function of Lowess\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "    # suppose this estimator has parameters \"f\", \"iter\" and \"intercept\"\n",
        "        return {\"f\": self.f, \"iter\": self.iter,\"intercept\":self.intercept}\n",
        "\n",
        "    def set_params(self, **parameters):\n",
        "        for parameter, value in parameters.items():\n",
        "            setattr(self, parameter, value)\n",
        "        return self"
      ],
      "metadata": {
        "id": "BqZGdNK2DnJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GradientBoosting:\n",
        "  def __init__(self, f = 1/3, epoch = 2, intercept = True, n_estimators = 3, scaler = None):\n",
        "    self.f = f\n",
        "    self.epoch = epoch\n",
        "    self.intercept = intercept\n",
        "    self.n_estimators = n_estimators\n",
        "    self.estimators = []\n",
        "    self.scaler = scaler\n",
        "    self._is_fitted = False\n",
        "\n",
        "  def fit(self, X, y, X_new):\n",
        "    self.estimators = []\n",
        "    residuals = y\n",
        "\n",
        "    if self.scaler != None:\n",
        "      self.X_scaled = self.scaler.fit_transform(X)\n",
        "      X_new_scaled = self.scaler.fit_transform(X_new)\n",
        "    else:\n",
        "      self.X_scaled = X\n",
        "      X_new_scaled = X_new\n",
        "\n",
        "    for _ in range(self.n_estimators): #loops for every estimator you want\n",
        "      model1 = Lowess_AG_MD(f=self.f, iter=self.epoch, intercept=self.intercept) #merged the boosted_lwr class so it is not being used now twice\n",
        "      model1.fit(self.X_scaled, residuals)\n",
        "      predictions1 = model1.predict(self.X_scaled)\n",
        "      residuals = residuals - predictions1\n",
        "\n",
        "      model2 = Lowess_AG_MD(f=self.f, iter=self.epoch, intercept=self.intercept)\n",
        "      model2.fit(self.X_scaled, residuals)\n",
        "\n",
        "      self.estimators.append((model1, model2))\n",
        "\n",
        "    self._is_fitted = True\n",
        "\n",
        "  def is_fitted(self):\n",
        "    return self._is_fitted\n",
        "\n",
        "  def predict(self, X):\n",
        "    if self.is_fitted():\n",
        "      if self.scaler != None:\n",
        "        self.X_new_scaled = self.scaler.transform(X)\n",
        "      else:\n",
        "        self.X_new_scaled = X\n",
        "\n",
        "      predictions = []\n",
        "      for model1, model2 in self.estimators:\n",
        "        predict1 = model1.predict(self.X_new_scaled)\n",
        "        predict2 = model2.predict(self.X_new_scaled)\n",
        "        predictions.append(predict1 + predict2)\n",
        "\n",
        "      return(predictions)\n",
        "\n",
        "    else:\n",
        "      return(self.is_fitted())"
      ],
      "metadata": {
        "id": "cGtLscCuyTJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Sophomore Year/DATA/DATA-310/Module 3/Regression Problems/Data/concrete.csv\")"
      ],
      "metadata": {
        "id": "8wqiLmjlEXRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = data.loc[:,'cement':'age'].values\n",
        "y = data['strength'].values"
      ],
      "metadata": {
        "id": "wtX6GO9sZApA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xtest, ytrain, ytest = tts(x,y,test_size=0.3,shuffle=True,random_state=123)"
      ],
      "metadata": {
        "id": "dHddKhl5mssz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "model = GradientBoosting(scaler = scaler)\n",
        "model.fit(X = xtrain, y = ytrain, X_new = xtest)\n",
        "model.is_fitted()\n",
        "model.predict(xtest)"
      ],
      "metadata": {
        "id": "HFP1gjxXYXHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MinMax Scaler\n",
        "scaler = MinMaxScaler()\n",
        "model = GradientBoosting(scaler = scaler)\n",
        "model.fit(X = xtrain, y = ytrain, X_new = xtest)\n",
        "model.is_fitted()\n",
        "model.predict(xtest)"
      ],
      "metadata": {
        "id": "VcsJMQ00ZAmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Quantile Scaler\n",
        "scaler = QuantileTransformer()\n",
        "model = GradientBoosting(scaler = scaler)\n",
        "model.fit(X = xtrain, y = ytrain, X_new = xtest)\n",
        "model.is_fitted()\n",
        "model.predict(xtest)"
      ],
      "metadata": {
        "id": "4Nk2LfgWZQxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_lwr = [] #Lowess\n",
        "mse_xgb = [] #XGBRegressor\n",
        "scale = QuantileTransformer(n_quantiles=900)\n",
        "\n",
        "kf = KFold(n_splits=10,shuffle=True,random_state=1234)\n",
        "\n",
        "model_xgb = XGBRegressor(objective ='reg:squarederror',n_estimators=100,reg_lambda=20,alpha=1,gamma=10,max_depth=4)\n",
        "\n",
        "model_lwr = GradientBoosting(scaler = scaler)\n",
        "\n",
        "for idxtrain, idxtest in kf.split(x):\n",
        "  xtrain = x[idxtrain]\n",
        "  ytrain = y[idxtrain]\n",
        "  ytest = y[idxtest]\n",
        "  xtest = x[idxtest]\n",
        "  xtrain = scale.fit_transform(xtrain)\n",
        "  xtest = scale.transform(xtest)\n",
        "\n",
        "  model_xgb.fit(xtrain,ytrain)\n",
        "  yhat_xgb = model_xgb.predict(xtest)\n",
        "\n",
        "  mse_xgb.append(mse(ytest,yhat_xgb))\n",
        "\n",
        "  model_lwr.fit(X = xtrain, y = ytrain, X_new = xtest)\n",
        "  yhat_lwr = model_lwr.predict(xtest)\n",
        "\n",
        "  mse_lwr.append(ytest,yhat_lwr)\n",
        "\n",
        "print('The Cross-validated Mean Squared Error for Locally Weighted Regression is : '+str(np.mean(mse_lwr)))\n",
        "print('The Cross-validated Mean Squared Error for XGB: '+str(np.mean(mse_xgb)))"
      ],
      "metadata": {
        "id": "75E0-z5FAj2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) U-Search\n"
      ],
      "metadata": {
        "id": "bm57n9ErD5ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class kNN:\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "        self.ss = StandardScaler()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = self.ss.fit_transform(X)\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for x_new in X:\n",
        "\n",
        "            x_new_scaled = self.ss.transform([x_new])\n",
        "\n",
        "            one_in_many = search(self.X_train, x_new_scaled, self.k, MetricKind.L2sq, exact=True)\n",
        "\n",
        "            distance_list = one_in_many.to_list()\n",
        "\n",
        "            nearest_indices = np.array(distance_list)[:, 0].astype('int64')\n",
        "\n",
        "            nearest_distances = np.array(distance_list)[:, 1].astype(float)\n",
        "\n",
        "            weights = 1 / nearest_distances\n",
        "\n",
        "            weights[weights == np.inf] = 100  # Avoid division by zero\n",
        "\n",
        "            weighted_sum = np.sum(weights)\n",
        "\n",
        "            if weighted_sum != 0: #ensuring the weights are not zero\n",
        "                predicted_value = np.sum(weights * self.y_train[nearest_indices]) / weighted_sum\n",
        "            else:\n",
        "                predicted_value = np.mean(self.y_train[nearest_indices]) #averaging the real y-values if the weights add to zero\n",
        "\n",
        "            predictions.append(predicted_value)\n",
        "\n",
        "        return predictions\n"
      ],
      "metadata": {
        "id": "5WzLeMQo_FR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data\n",
        "\n",
        "x = data.loc[:,'cement':'age'].values\n",
        "\n",
        "y = data['strength'].values"
      ],
      "metadata": {
        "id": "egyBkBu1Llep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = kNN(5)"
      ],
      "metadata": {
        "id": "RNZNChMVav3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y)"
      ],
      "metadata": {
        "id": "E48TSDcbkkJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(x)"
      ],
      "metadata": {
        "id": "_HaP8zQUuyIN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}